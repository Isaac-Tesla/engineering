{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "32872b2965b3fdb9893d43fb0567e4535117f4b0"
   },
   "source": [
    "<h1>**Part 1 Binary Classification**</h1>\n",
    "<h1>1.1 Data Munging</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "### Import libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import decimal\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "c09c82c85569ee28013b8ffb7894dbcef8efb947"
   },
   "outputs": [],
   "source": [
    "### Read the training and testing data. Print the number of features in the dataset.\n",
    "Wisconsin_Breast_cancer_test = pd.read_csv(\"~/data/test_wbcd.csv\")\n",
    "Wisconsin_Breast_cancer_train = pd.read_csv(\"~/data/train_wbcd.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features: 32\n"
     ]
    }
   ],
   "source": [
    "### List features\n",
    "n_features = Wisconsin_Breast_cancer_test.shape[1]\n",
    "print(\"number of features: %d\" % n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features: 32\n"
     ]
    }
   ],
   "source": [
    "n_features = Wisconsin_Breast_cancer_train.shape[1]\n",
    "print(\"number of features: %d\" % n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "ab62066154c5899dddc8ebe059ebd7e530b4c60b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>f29</th>\n",
       "      <th>f30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>894047</td>\n",
       "      <td>B</td>\n",
       "      <td>8.597</td>\n",
       "      <td>18.60</td>\n",
       "      <td>54.09</td>\n",
       "      <td>221.2</td>\n",
       "      <td>0.10740</td>\n",
       "      <td>0.05847</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.952</td>\n",
       "      <td>22.44</td>\n",
       "      <td>56.65</td>\n",
       "      <td>240.1</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>0.07767</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.3142</td>\n",
       "      <td>0.08116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892189</td>\n",
       "      <td>M</td>\n",
       "      <td>11.760</td>\n",
       "      <td>18.14</td>\n",
       "      <td>75.00</td>\n",
       "      <td>431.1</td>\n",
       "      <td>0.09968</td>\n",
       "      <td>0.05914</td>\n",
       "      <td>0.02685</td>\n",
       "      <td>0.03515</td>\n",
       "      <td>...</td>\n",
       "      <td>13.360</td>\n",
       "      <td>23.39</td>\n",
       "      <td>85.10</td>\n",
       "      <td>553.6</td>\n",
       "      <td>0.1137</td>\n",
       "      <td>0.07974</td>\n",
       "      <td>0.06120</td>\n",
       "      <td>0.07160</td>\n",
       "      <td>0.1978</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8810528</td>\n",
       "      <td>B</td>\n",
       "      <td>11.840</td>\n",
       "      <td>18.94</td>\n",
       "      <td>75.51</td>\n",
       "      <td>428.0</td>\n",
       "      <td>0.08871</td>\n",
       "      <td>0.06900</td>\n",
       "      <td>0.02669</td>\n",
       "      <td>0.01393</td>\n",
       "      <td>...</td>\n",
       "      <td>13.300</td>\n",
       "      <td>24.99</td>\n",
       "      <td>85.22</td>\n",
       "      <td>546.3</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>0.18800</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.06913</td>\n",
       "      <td>0.2535</td>\n",
       "      <td>0.07993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>905978</td>\n",
       "      <td>B</td>\n",
       "      <td>9.405</td>\n",
       "      <td>21.70</td>\n",
       "      <td>59.60</td>\n",
       "      <td>271.2</td>\n",
       "      <td>0.10440</td>\n",
       "      <td>0.06159</td>\n",
       "      <td>0.02047</td>\n",
       "      <td>0.01257</td>\n",
       "      <td>...</td>\n",
       "      <td>10.850</td>\n",
       "      <td>31.24</td>\n",
       "      <td>68.73</td>\n",
       "      <td>359.4</td>\n",
       "      <td>0.1526</td>\n",
       "      <td>0.11930</td>\n",
       "      <td>0.06141</td>\n",
       "      <td>0.03770</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>0.08304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>871001502</td>\n",
       "      <td>B</td>\n",
       "      <td>8.219</td>\n",
       "      <td>20.70</td>\n",
       "      <td>53.27</td>\n",
       "      <td>203.9</td>\n",
       "      <td>0.09405</td>\n",
       "      <td>0.13050</td>\n",
       "      <td>0.13210</td>\n",
       "      <td>0.02168</td>\n",
       "      <td>...</td>\n",
       "      <td>9.092</td>\n",
       "      <td>29.72</td>\n",
       "      <td>58.08</td>\n",
       "      <td>249.8</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>0.53810</td>\n",
       "      <td>0.07879</td>\n",
       "      <td>0.3322</td>\n",
       "      <td>0.14860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient_ID Diagnosis      f1     f2     f3     f4       f5       f6  \\\n",
       "0      894047         B   8.597  18.60  54.09  221.2  0.10740  0.05847   \n",
       "1      892189         M  11.760  18.14  75.00  431.1  0.09968  0.05914   \n",
       "2     8810528         B  11.840  18.94  75.51  428.0  0.08871  0.06900   \n",
       "3      905978         B   9.405  21.70  59.60  271.2  0.10440  0.06159   \n",
       "4   871001502         B   8.219  20.70  53.27  203.9  0.09405  0.13050   \n",
       "\n",
       "        f7       f8   ...        f21    f22    f23    f24     f25      f26  \\\n",
       "0  0.00000  0.00000   ...      8.952  22.44  56.65  240.1  0.1347  0.07767   \n",
       "1  0.02685  0.03515   ...     13.360  23.39  85.10  553.6  0.1137  0.07974   \n",
       "2  0.02669  0.01393   ...     13.300  24.99  85.22  546.3  0.1280  0.18800   \n",
       "3  0.02047  0.01257   ...     10.850  31.24  68.73  359.4  0.1526  0.11930   \n",
       "4  0.13210  0.02168   ...      9.092  29.72  58.08  249.8  0.1630  0.43100   \n",
       "\n",
       "       f27      f28     f29      f30  \n",
       "0  0.00000  0.00000  0.3142  0.08116  \n",
       "1  0.06120  0.07160  0.1978  0.06915  \n",
       "2  0.14710  0.06913  0.2535  0.07993  \n",
       "3  0.06141  0.03770  0.2872  0.08304  \n",
       "4  0.53810  0.07879  0.3322  0.14860  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Preview the datasets\n",
    "Wisconsin_Breast_cancer_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "7c655c498beeb94b266c1e23f9167ea9816548bc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>f29</th>\n",
       "      <th>f30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>909410</td>\n",
       "      <td>B</td>\n",
       "      <td>14.02</td>\n",
       "      <td>15.66</td>\n",
       "      <td>89.59</td>\n",
       "      <td>606.5</td>\n",
       "      <td>0.07966</td>\n",
       "      <td>0.05581</td>\n",
       "      <td>0.02087</td>\n",
       "      <td>0.02652</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>19.31</td>\n",
       "      <td>96.53</td>\n",
       "      <td>688.9</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.06260</td>\n",
       "      <td>0.08216</td>\n",
       "      <td>0.2136</td>\n",
       "      <td>0.06710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8912284</td>\n",
       "      <td>B</td>\n",
       "      <td>12.89</td>\n",
       "      <td>15.70</td>\n",
       "      <td>84.08</td>\n",
       "      <td>516.6</td>\n",
       "      <td>0.07818</td>\n",
       "      <td>0.09580</td>\n",
       "      <td>0.11150</td>\n",
       "      <td>0.03390</td>\n",
       "      <td>...</td>\n",
       "      <td>13.90</td>\n",
       "      <td>19.69</td>\n",
       "      <td>92.12</td>\n",
       "      <td>595.6</td>\n",
       "      <td>0.09926</td>\n",
       "      <td>0.2317</td>\n",
       "      <td>0.33440</td>\n",
       "      <td>0.10170</td>\n",
       "      <td>0.1999</td>\n",
       "      <td>0.07127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90317302</td>\n",
       "      <td>B</td>\n",
       "      <td>10.26</td>\n",
       "      <td>12.22</td>\n",
       "      <td>65.75</td>\n",
       "      <td>321.6</td>\n",
       "      <td>0.09996</td>\n",
       "      <td>0.07542</td>\n",
       "      <td>0.01923</td>\n",
       "      <td>0.01968</td>\n",
       "      <td>...</td>\n",
       "      <td>11.38</td>\n",
       "      <td>15.65</td>\n",
       "      <td>73.23</td>\n",
       "      <td>394.5</td>\n",
       "      <td>0.13430</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.08615</td>\n",
       "      <td>0.06696</td>\n",
       "      <td>0.2937</td>\n",
       "      <td>0.07722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>914102</td>\n",
       "      <td>B</td>\n",
       "      <td>13.16</td>\n",
       "      <td>20.54</td>\n",
       "      <td>84.06</td>\n",
       "      <td>538.7</td>\n",
       "      <td>0.07335</td>\n",
       "      <td>0.05275</td>\n",
       "      <td>0.01800</td>\n",
       "      <td>0.01256</td>\n",
       "      <td>...</td>\n",
       "      <td>14.50</td>\n",
       "      <td>28.46</td>\n",
       "      <td>95.29</td>\n",
       "      <td>648.3</td>\n",
       "      <td>0.11180</td>\n",
       "      <td>0.1646</td>\n",
       "      <td>0.07698</td>\n",
       "      <td>0.04195</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>0.07429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient_ID Diagnosis     f1     f2      f3      f4       f5       f6  \\\n",
       "0      909410         B  14.02  15.66   89.59   606.5  0.07966  0.05581   \n",
       "1    84358402         M  20.29  14.34  135.10  1297.0  0.10030  0.13280   \n",
       "2     8912284         B  12.89  15.70   84.08   516.6  0.07818  0.09580   \n",
       "3    90317302         B  10.26  12.22   65.75   321.6  0.09996  0.07542   \n",
       "4      914102         B  13.16  20.54   84.06   538.7  0.07335  0.05275   \n",
       "\n",
       "        f7       f8   ...       f21    f22     f23     f24      f25     f26  \\\n",
       "0  0.02087  0.02652   ...     14.91  19.31   96.53   688.9  0.10340  0.1017   \n",
       "1  0.19800  0.10430   ...     22.54  16.67  152.20  1575.0  0.13740  0.2050   \n",
       "2  0.11150  0.03390   ...     13.90  19.69   92.12   595.6  0.09926  0.2317   \n",
       "3  0.01923  0.01968   ...     11.38  15.65   73.23   394.5  0.13430  0.1650   \n",
       "4  0.01800  0.01256   ...     14.50  28.46   95.29   648.3  0.11180  0.1646   \n",
       "\n",
       "       f27      f28     f29      f30  \n",
       "0  0.06260  0.08216  0.2136  0.06710  \n",
       "1  0.40000  0.16250  0.2364  0.07678  \n",
       "2  0.33440  0.10170  0.1999  0.07127  \n",
       "3  0.08615  0.06696  0.2937  0.07722  \n",
       "4  0.07698  0.04195  0.2687  0.07429  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wisconsin_Breast_cancer_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "### For the data label, print the total number of 1's and 0's in the training and testing data.\n",
    "# Data label is B or M in \"Diagnosis\", convert to 1 and 0, B = 1, M = 0\n",
    "breastCancertest = Wisconsin_Breast_cancer_test.Diagnosis == 'B'\n",
    "malignantTest = Wisconsin_Breast_cancer_test.Diagnosis == 'M'\n",
    "breastCancertrain = Wisconsin_Breast_cancer_train.Diagnosis == 'B'\n",
    "malignantTrain = Wisconsin_Breast_cancer_train.Diagnosis == 'M'\n",
    "column_name = 'Diagnosis'\n",
    "Wisconsin_Breast_cancer_test.loc[breastCancertest, column_name] = 1\n",
    "Wisconsin_Breast_cancer_test.loc[malignantTest, column_name] = 0\n",
    "Wisconsin_Breast_cancer_train.loc[breastCancertrain, column_name] = 1\n",
    "Wisconsin_Breast_cancer_train.loc[malignantTrain, column_name] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "f6a68ae4a8837564590e3d42b4c9158e107c58ca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>f29</th>\n",
       "      <th>f30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>894047</td>\n",
       "      <td>1</td>\n",
       "      <td>8.597</td>\n",
       "      <td>18.60</td>\n",
       "      <td>54.09</td>\n",
       "      <td>221.2</td>\n",
       "      <td>0.10740</td>\n",
       "      <td>0.05847</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.952</td>\n",
       "      <td>22.44</td>\n",
       "      <td>56.65</td>\n",
       "      <td>240.1</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>0.07767</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.3142</td>\n",
       "      <td>0.08116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>892189</td>\n",
       "      <td>0</td>\n",
       "      <td>11.760</td>\n",
       "      <td>18.14</td>\n",
       "      <td>75.00</td>\n",
       "      <td>431.1</td>\n",
       "      <td>0.09968</td>\n",
       "      <td>0.05914</td>\n",
       "      <td>0.02685</td>\n",
       "      <td>0.03515</td>\n",
       "      <td>...</td>\n",
       "      <td>13.360</td>\n",
       "      <td>23.39</td>\n",
       "      <td>85.10</td>\n",
       "      <td>553.6</td>\n",
       "      <td>0.1137</td>\n",
       "      <td>0.07974</td>\n",
       "      <td>0.06120</td>\n",
       "      <td>0.07160</td>\n",
       "      <td>0.1978</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8810528</td>\n",
       "      <td>1</td>\n",
       "      <td>11.840</td>\n",
       "      <td>18.94</td>\n",
       "      <td>75.51</td>\n",
       "      <td>428.0</td>\n",
       "      <td>0.08871</td>\n",
       "      <td>0.06900</td>\n",
       "      <td>0.02669</td>\n",
       "      <td>0.01393</td>\n",
       "      <td>...</td>\n",
       "      <td>13.300</td>\n",
       "      <td>24.99</td>\n",
       "      <td>85.22</td>\n",
       "      <td>546.3</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>0.18800</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.06913</td>\n",
       "      <td>0.2535</td>\n",
       "      <td>0.07993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>905978</td>\n",
       "      <td>1</td>\n",
       "      <td>9.405</td>\n",
       "      <td>21.70</td>\n",
       "      <td>59.60</td>\n",
       "      <td>271.2</td>\n",
       "      <td>0.10440</td>\n",
       "      <td>0.06159</td>\n",
       "      <td>0.02047</td>\n",
       "      <td>0.01257</td>\n",
       "      <td>...</td>\n",
       "      <td>10.850</td>\n",
       "      <td>31.24</td>\n",
       "      <td>68.73</td>\n",
       "      <td>359.4</td>\n",
       "      <td>0.1526</td>\n",
       "      <td>0.11930</td>\n",
       "      <td>0.06141</td>\n",
       "      <td>0.03770</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>0.08304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>871001502</td>\n",
       "      <td>1</td>\n",
       "      <td>8.219</td>\n",
       "      <td>20.70</td>\n",
       "      <td>53.27</td>\n",
       "      <td>203.9</td>\n",
       "      <td>0.09405</td>\n",
       "      <td>0.13050</td>\n",
       "      <td>0.13210</td>\n",
       "      <td>0.02168</td>\n",
       "      <td>...</td>\n",
       "      <td>9.092</td>\n",
       "      <td>29.72</td>\n",
       "      <td>58.08</td>\n",
       "      <td>249.8</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>0.53810</td>\n",
       "      <td>0.07879</td>\n",
       "      <td>0.3322</td>\n",
       "      <td>0.14860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient_ID  Diagnosis      f1     f2     f3     f4       f5       f6  \\\n",
       "0      894047          1   8.597  18.60  54.09  221.2  0.10740  0.05847   \n",
       "1      892189          0  11.760  18.14  75.00  431.1  0.09968  0.05914   \n",
       "2     8810528          1  11.840  18.94  75.51  428.0  0.08871  0.06900   \n",
       "3      905978          1   9.405  21.70  59.60  271.2  0.10440  0.06159   \n",
       "4   871001502          1   8.219  20.70  53.27  203.9  0.09405  0.13050   \n",
       "\n",
       "        f7       f8   ...        f21    f22    f23    f24     f25      f26  \\\n",
       "0  0.00000  0.00000   ...      8.952  22.44  56.65  240.1  0.1347  0.07767   \n",
       "1  0.02685  0.03515   ...     13.360  23.39  85.10  553.6  0.1137  0.07974   \n",
       "2  0.02669  0.01393   ...     13.300  24.99  85.22  546.3  0.1280  0.18800   \n",
       "3  0.02047  0.01257   ...     10.850  31.24  68.73  359.4  0.1526  0.11930   \n",
       "4  0.13210  0.02168   ...      9.092  29.72  58.08  249.8  0.1630  0.43100   \n",
       "\n",
       "       f27      f28     f29      f30  \n",
       "0  0.00000  0.00000  0.3142  0.08116  \n",
       "1  0.06120  0.07160  0.1978  0.06915  \n",
       "2  0.14710  0.06913  0.2535  0.07993  \n",
       "3  0.06141  0.03770  0.2872  0.08304  \n",
       "4  0.53810  0.07879  0.3322  0.14860  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Preview the change\n",
    "Wisconsin_Breast_cancer_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "bb1eb0de6d422ce12ae4b5dd7b3d71d8e035f36c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "      <th>f25</th>\n",
       "      <th>f26</th>\n",
       "      <th>f27</th>\n",
       "      <th>f28</th>\n",
       "      <th>f29</th>\n",
       "      <th>f30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>909410</td>\n",
       "      <td>1</td>\n",
       "      <td>14.02</td>\n",
       "      <td>15.66</td>\n",
       "      <td>89.59</td>\n",
       "      <td>606.5</td>\n",
       "      <td>0.07966</td>\n",
       "      <td>0.05581</td>\n",
       "      <td>0.02087</td>\n",
       "      <td>0.02652</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>19.31</td>\n",
       "      <td>96.53</td>\n",
       "      <td>688.9</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.06260</td>\n",
       "      <td>0.08216</td>\n",
       "      <td>0.2136</td>\n",
       "      <td>0.06710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84358402</td>\n",
       "      <td>0</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8912284</td>\n",
       "      <td>1</td>\n",
       "      <td>12.89</td>\n",
       "      <td>15.70</td>\n",
       "      <td>84.08</td>\n",
       "      <td>516.6</td>\n",
       "      <td>0.07818</td>\n",
       "      <td>0.09580</td>\n",
       "      <td>0.11150</td>\n",
       "      <td>0.03390</td>\n",
       "      <td>...</td>\n",
       "      <td>13.90</td>\n",
       "      <td>19.69</td>\n",
       "      <td>92.12</td>\n",
       "      <td>595.6</td>\n",
       "      <td>0.09926</td>\n",
       "      <td>0.2317</td>\n",
       "      <td>0.33440</td>\n",
       "      <td>0.10170</td>\n",
       "      <td>0.1999</td>\n",
       "      <td>0.07127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90317302</td>\n",
       "      <td>1</td>\n",
       "      <td>10.26</td>\n",
       "      <td>12.22</td>\n",
       "      <td>65.75</td>\n",
       "      <td>321.6</td>\n",
       "      <td>0.09996</td>\n",
       "      <td>0.07542</td>\n",
       "      <td>0.01923</td>\n",
       "      <td>0.01968</td>\n",
       "      <td>...</td>\n",
       "      <td>11.38</td>\n",
       "      <td>15.65</td>\n",
       "      <td>73.23</td>\n",
       "      <td>394.5</td>\n",
       "      <td>0.13430</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.08615</td>\n",
       "      <td>0.06696</td>\n",
       "      <td>0.2937</td>\n",
       "      <td>0.07722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>914102</td>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>20.54</td>\n",
       "      <td>84.06</td>\n",
       "      <td>538.7</td>\n",
       "      <td>0.07335</td>\n",
       "      <td>0.05275</td>\n",
       "      <td>0.01800</td>\n",
       "      <td>0.01256</td>\n",
       "      <td>...</td>\n",
       "      <td>14.50</td>\n",
       "      <td>28.46</td>\n",
       "      <td>95.29</td>\n",
       "      <td>648.3</td>\n",
       "      <td>0.11180</td>\n",
       "      <td>0.1646</td>\n",
       "      <td>0.07698</td>\n",
       "      <td>0.04195</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>0.07429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient_ID  Diagnosis     f1     f2      f3      f4       f5       f6  \\\n",
       "0      909410          1  14.02  15.66   89.59   606.5  0.07966  0.05581   \n",
       "1    84358402          0  20.29  14.34  135.10  1297.0  0.10030  0.13280   \n",
       "2     8912284          1  12.89  15.70   84.08   516.6  0.07818  0.09580   \n",
       "3    90317302          1  10.26  12.22   65.75   321.6  0.09996  0.07542   \n",
       "4      914102          1  13.16  20.54   84.06   538.7  0.07335  0.05275   \n",
       "\n",
       "        f7       f8   ...       f21    f22     f23     f24      f25     f26  \\\n",
       "0  0.02087  0.02652   ...     14.91  19.31   96.53   688.9  0.10340  0.1017   \n",
       "1  0.19800  0.10430   ...     22.54  16.67  152.20  1575.0  0.13740  0.2050   \n",
       "2  0.11150  0.03390   ...     13.90  19.69   92.12   595.6  0.09926  0.2317   \n",
       "3  0.01923  0.01968   ...     11.38  15.65   73.23   394.5  0.13430  0.1650   \n",
       "4  0.01800  0.01256   ...     14.50  28.46   95.29   648.3  0.11180  0.1646   \n",
       "\n",
       "       f27      f28     f29      f30  \n",
       "0  0.06260  0.08216  0.2136  0.06710  \n",
       "1  0.40000  0.16250  0.2364  0.07678  \n",
       "2  0.33440  0.10170  0.1999  0.07127  \n",
       "3  0.08615  0.06696  0.2937  0.07722  \n",
       "4  0.07698  0.04195  0.2687  0.07429  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wisconsin_Breast_cancer_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "ed3a881270d004d8e14ece0a20dbe53797b44a33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1], dtype=int64), array([42, 58], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "### Data points for each class\n",
    "print(np.unique(Wisconsin_Breast_cancer_train.Diagnosis, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7e6038f2e5e6c95097f1d173bd03c22b5c7d1b05"
   },
   "source": [
    "42 malignant and 58 breast cancer. Fairly well balanced training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "41868ceb2a16bf2df416322c0775c5b3fc746224"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1], dtype=int64), array([ 6, 14], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(Wisconsin_Breast_cancer_test.Diagnosis, return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b572550f9103c7120f56939c0d58068343e8e9d2"
   },
   "source": [
    "6 malignant and 14 breast cancer. Unbalanced test data with more than twice the amount of breast cancer compared to malignant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "887deffbab27c9a1368dc1d3bdf9e89e0a7e871f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient_ID    0\n",
      "Diagnosis     0\n",
      "f1            0\n",
      "f2            0\n",
      "f3            0\n",
      "f4            0\n",
      "f5            0\n",
      "f6            0\n",
      "f7            0\n",
      "f8            0\n",
      "f9            0\n",
      "f10           0\n",
      "f11           0\n",
      "f12           0\n",
      "f13           0\n",
      "f14           0\n",
      "f15           0\n",
      "f16           0\n",
      "f17           0\n",
      "f18           0\n",
      "f19           0\n",
      "f20           0\n",
      "f21           2\n",
      "f22           0\n",
      "f23           0\n",
      "f24           0\n",
      "f25           0\n",
      "f26           0\n",
      "f27           0\n",
      "f28           0\n",
      "f29           0\n",
      "f30           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Print the number of features with missing entries.\n",
    "print(np.isnan(Wisconsin_Breast_cancer_train).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4d1d85054b2ea1d75767d68a10f26f62ff35388a"
   },
   "source": [
    "From our training dataset we can see only 2 counts of missing data for 'f21'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "dce77447e5f09f56485f3b312912f763a857c27d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient_ID    0\n",
      "Diagnosis     0\n",
      "f1            0\n",
      "f2            0\n",
      "f3            0\n",
      "f4            0\n",
      "f5            0\n",
      "f6            0\n",
      "f7            0\n",
      "f8            0\n",
      "f9            0\n",
      "f10           0\n",
      "f11           0\n",
      "f12           0\n",
      "f13           0\n",
      "f14           0\n",
      "f15           0\n",
      "f16           0\n",
      "f17           0\n",
      "f18           0\n",
      "f19           0\n",
      "f20           0\n",
      "f21           1\n",
      "f22           0\n",
      "f23           0\n",
      "f24           0\n",
      "f25           0\n",
      "f26           0\n",
      "f27           0\n",
      "f28           0\n",
      "f29           0\n",
      "f30           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(Wisconsin_Breast_cancer_test).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8f3e8b1146d173108fa0327cd47a32f2e4d450cb"
   },
   "source": [
    "In our test set we can see only 1 count of missing data in 'f21'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "74dd7f1105152dc2399aa289dde3edaa17ed969c"
   },
   "outputs": [],
   "source": [
    "f21_mean_train = np.mean(Wisconsin_Breast_cancer_train['f21'])\n",
    "#print(f21_mean_train)\n",
    "Wisconsin_Breast_cancer_train['f21'] = Wisconsin_Breast_cancer_train['f21'].fillna(f21_mean_train)\n",
    "Wisconsin_Breast_cancer_test['f21'] = Wisconsin_Breast_cancer_test['f21'].fillna(f21_mean_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "0710caff4a60a157f7bad4f8d9effb3355968f74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient_ID    0\n",
      "Diagnosis     0\n",
      "f1            0\n",
      "f2            0\n",
      "f3            0\n",
      "f4            0\n",
      "f5            0\n",
      "f6            0\n",
      "f7            0\n",
      "f8            0\n",
      "f9            0\n",
      "f10           0\n",
      "f11           0\n",
      "f12           0\n",
      "f13           0\n",
      "f14           0\n",
      "f15           0\n",
      "f16           0\n",
      "f17           0\n",
      "f18           0\n",
      "f19           0\n",
      "f20           0\n",
      "f21           0\n",
      "f22           0\n",
      "f23           0\n",
      "f24           0\n",
      "f25           0\n",
      "f26           0\n",
      "f27           0\n",
      "f28           0\n",
      "f29           0\n",
      "f30           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Confirm fillna operation.\n",
    "print(np.isnan(Wisconsin_Breast_cancer_test).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "e6e8e47c28456619512ebd7f2508c195b36bc0b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient_ID    0\n",
      "Diagnosis     0\n",
      "f1            0\n",
      "f2            0\n",
      "f3            0\n",
      "f4            0\n",
      "f5            0\n",
      "f6            0\n",
      "f7            0\n",
      "f8            0\n",
      "f9            0\n",
      "f10           0\n",
      "f11           0\n",
      "f12           0\n",
      "f13           0\n",
      "f14           0\n",
      "f15           0\n",
      "f16           0\n",
      "f17           0\n",
      "f18           0\n",
      "f19           0\n",
      "f20           0\n",
      "f21           0\n",
      "f22           0\n",
      "f23           0\n",
      "f24           0\n",
      "f25           0\n",
      "f26           0\n",
      "f27           0\n",
      "f28           0\n",
      "f29           0\n",
      "f30           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(Wisconsin_Breast_cancer_train).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "35a1d799efa8e852597ec73b35f627cbca4b97db"
   },
   "outputs": [],
   "source": [
    "### Split into X_train, Y_train, X_test, Y_test pairs\n",
    "X_train = Wisconsin_Breast_cancer_train.values[:,2:]\n",
    "Y_train = Wisconsin_Breast_cancer_train.values[:,1]\n",
    "X_test = Wisconsin_Breast_cancer_test.values[:,2:]\n",
    "Y_test = Wisconsin_Breast_cancer_test.values[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "2d25aba3b80c85fc4f54386b1ec2956a42f2ca0f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.02</td>\n",
       "      <td>15.66</td>\n",
       "      <td>89.59</td>\n",
       "      <td>606.5</td>\n",
       "      <td>0.07966</td>\n",
       "      <td>0.05581</td>\n",
       "      <td>0.02087</td>\n",
       "      <td>0.02652</td>\n",
       "      <td>0.1589</td>\n",
       "      <td>0.05586</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>19.31</td>\n",
       "      <td>96.53</td>\n",
       "      <td>688.9</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.06260</td>\n",
       "      <td>0.08216</td>\n",
       "      <td>0.2136</td>\n",
       "      <td>0.06710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.89</td>\n",
       "      <td>15.70</td>\n",
       "      <td>84.08</td>\n",
       "      <td>516.6</td>\n",
       "      <td>0.07818</td>\n",
       "      <td>0.09580</td>\n",
       "      <td>0.11150</td>\n",
       "      <td>0.03390</td>\n",
       "      <td>0.1432</td>\n",
       "      <td>0.05935</td>\n",
       "      <td>...</td>\n",
       "      <td>13.90</td>\n",
       "      <td>19.69</td>\n",
       "      <td>92.12</td>\n",
       "      <td>595.6</td>\n",
       "      <td>0.09926</td>\n",
       "      <td>0.2317</td>\n",
       "      <td>0.33440</td>\n",
       "      <td>0.10170</td>\n",
       "      <td>0.1999</td>\n",
       "      <td>0.07127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.26</td>\n",
       "      <td>12.22</td>\n",
       "      <td>65.75</td>\n",
       "      <td>321.6</td>\n",
       "      <td>0.09996</td>\n",
       "      <td>0.07542</td>\n",
       "      <td>0.01923</td>\n",
       "      <td>0.01968</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.06569</td>\n",
       "      <td>...</td>\n",
       "      <td>11.38</td>\n",
       "      <td>15.65</td>\n",
       "      <td>73.23</td>\n",
       "      <td>394.5</td>\n",
       "      <td>0.13430</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.08615</td>\n",
       "      <td>0.06696</td>\n",
       "      <td>0.2937</td>\n",
       "      <td>0.07722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.16</td>\n",
       "      <td>20.54</td>\n",
       "      <td>84.06</td>\n",
       "      <td>538.7</td>\n",
       "      <td>0.07335</td>\n",
       "      <td>0.05275</td>\n",
       "      <td>0.01800</td>\n",
       "      <td>0.01256</td>\n",
       "      <td>0.1713</td>\n",
       "      <td>0.05888</td>\n",
       "      <td>...</td>\n",
       "      <td>14.50</td>\n",
       "      <td>28.46</td>\n",
       "      <td>95.29</td>\n",
       "      <td>648.3</td>\n",
       "      <td>0.11180</td>\n",
       "      <td>0.1646</td>\n",
       "      <td>0.07698</td>\n",
       "      <td>0.04195</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>0.07429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1       2       3        4        5        6        7       8   \\\n",
       "0  14.02  15.66   89.59   606.5  0.07966  0.05581  0.02087  0.02652  0.1589   \n",
       "1  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800  0.10430  0.1809   \n",
       "2  12.89  15.70   84.08   516.6  0.07818  0.09580  0.11150  0.03390  0.1432   \n",
       "3  10.26  12.22   65.75   321.6  0.09996  0.07542  0.01923  0.01968  0.1800   \n",
       "4  13.16  20.54   84.06   538.7  0.07335  0.05275  0.01800  0.01256  0.1713   \n",
       "\n",
       "        9    ...        20     21      22      23       24      25       26  \\\n",
       "0  0.05586   ...     14.91  19.31   96.53   688.9  0.10340  0.1017  0.06260   \n",
       "1  0.05883   ...     22.54  16.67  152.20  1575.0  0.13740  0.2050  0.40000   \n",
       "2  0.05935   ...     13.90  19.69   92.12   595.6  0.09926  0.2317  0.33440   \n",
       "3  0.06569   ...     11.38  15.65   73.23   394.5  0.13430  0.1650  0.08615   \n",
       "4  0.05888   ...     14.50  28.46   95.29   648.3  0.11180  0.1646  0.07698   \n",
       "\n",
       "        27      28       29  \n",
       "0  0.08216  0.2136  0.06710  \n",
       "1  0.16250  0.2364  0.07678  \n",
       "2  0.10170  0.1999  0.07127  \n",
       "3  0.06696  0.2937  0.07722  \n",
       "4  0.04195  0.2687  0.07429  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "fea6bc38f9252b5f70c1a7f2621ef2c92e1cda8e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0  1.0\n",
       "1  0.0\n",
       "2  1.0\n",
       "3  1.0\n",
       "4  1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Y_train).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "9e0c4d51de38d0f8ed35f013cc4d21012da9c711"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.597</td>\n",
       "      <td>18.60</td>\n",
       "      <td>54.09</td>\n",
       "      <td>221.2</td>\n",
       "      <td>0.10740</td>\n",
       "      <td>0.05847</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.2163</td>\n",
       "      <td>0.07359</td>\n",
       "      <td>...</td>\n",
       "      <td>8.952</td>\n",
       "      <td>22.44</td>\n",
       "      <td>56.65</td>\n",
       "      <td>240.1</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>0.07767</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.3142</td>\n",
       "      <td>0.08116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.760</td>\n",
       "      <td>18.14</td>\n",
       "      <td>75.00</td>\n",
       "      <td>431.1</td>\n",
       "      <td>0.09968</td>\n",
       "      <td>0.05914</td>\n",
       "      <td>0.02685</td>\n",
       "      <td>0.03515</td>\n",
       "      <td>0.1619</td>\n",
       "      <td>0.06287</td>\n",
       "      <td>...</td>\n",
       "      <td>13.360</td>\n",
       "      <td>23.39</td>\n",
       "      <td>85.10</td>\n",
       "      <td>553.6</td>\n",
       "      <td>0.1137</td>\n",
       "      <td>0.07974</td>\n",
       "      <td>0.06120</td>\n",
       "      <td>0.07160</td>\n",
       "      <td>0.1978</td>\n",
       "      <td>0.06915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.840</td>\n",
       "      <td>18.94</td>\n",
       "      <td>75.51</td>\n",
       "      <td>428.0</td>\n",
       "      <td>0.08871</td>\n",
       "      <td>0.06900</td>\n",
       "      <td>0.02669</td>\n",
       "      <td>0.01393</td>\n",
       "      <td>0.1533</td>\n",
       "      <td>0.06057</td>\n",
       "      <td>...</td>\n",
       "      <td>13.300</td>\n",
       "      <td>24.99</td>\n",
       "      <td>85.22</td>\n",
       "      <td>546.3</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>0.18800</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.06913</td>\n",
       "      <td>0.2535</td>\n",
       "      <td>0.07993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.405</td>\n",
       "      <td>21.70</td>\n",
       "      <td>59.60</td>\n",
       "      <td>271.2</td>\n",
       "      <td>0.10440</td>\n",
       "      <td>0.06159</td>\n",
       "      <td>0.02047</td>\n",
       "      <td>0.01257</td>\n",
       "      <td>0.2025</td>\n",
       "      <td>0.06601</td>\n",
       "      <td>...</td>\n",
       "      <td>10.850</td>\n",
       "      <td>31.24</td>\n",
       "      <td>68.73</td>\n",
       "      <td>359.4</td>\n",
       "      <td>0.1526</td>\n",
       "      <td>0.11930</td>\n",
       "      <td>0.06141</td>\n",
       "      <td>0.03770</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>0.08304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.219</td>\n",
       "      <td>20.70</td>\n",
       "      <td>53.27</td>\n",
       "      <td>203.9</td>\n",
       "      <td>0.09405</td>\n",
       "      <td>0.13050</td>\n",
       "      <td>0.13210</td>\n",
       "      <td>0.02168</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>0.08261</td>\n",
       "      <td>...</td>\n",
       "      <td>9.092</td>\n",
       "      <td>29.72</td>\n",
       "      <td>58.08</td>\n",
       "      <td>249.8</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>0.53810</td>\n",
       "      <td>0.07879</td>\n",
       "      <td>0.3322</td>\n",
       "      <td>0.14860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2      3        4        5        6        7       8   \\\n",
       "0   8.597  18.60  54.09  221.2  0.10740  0.05847  0.00000  0.00000  0.2163   \n",
       "1  11.760  18.14  75.00  431.1  0.09968  0.05914  0.02685  0.03515  0.1619   \n",
       "2  11.840  18.94  75.51  428.0  0.08871  0.06900  0.02669  0.01393  0.1533   \n",
       "3   9.405  21.70  59.60  271.2  0.10440  0.06159  0.02047  0.01257  0.2025   \n",
       "4   8.219  20.70  53.27  203.9  0.09405  0.13050  0.13210  0.02168  0.2222   \n",
       "\n",
       "        9    ...         20     21     22     23      24       25       26  \\\n",
       "0  0.07359   ...      8.952  22.44  56.65  240.1  0.1347  0.07767  0.00000   \n",
       "1  0.06287   ...     13.360  23.39  85.10  553.6  0.1137  0.07974  0.06120   \n",
       "2  0.06057   ...     13.300  24.99  85.22  546.3  0.1280  0.18800  0.14710   \n",
       "3  0.06601   ...     10.850  31.24  68.73  359.4  0.1526  0.11930  0.06141   \n",
       "4  0.08261   ...      9.092  29.72  58.08  249.8  0.1630  0.43100  0.53810   \n",
       "\n",
       "        27      28       29  \n",
       "0  0.00000  0.3142  0.08116  \n",
       "1  0.07160  0.1978  0.06915  \n",
       "2  0.06913  0.2535  0.07993  \n",
       "3  0.03770  0.2872  0.08304  \n",
       "4  0.07879  0.3322  0.14860  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_test).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "34b36ad6c2b0fb4c9751a1970543b9005c3fa640"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0  1.0\n",
       "1  0.0\n",
       "2  1.0\n",
       "3  1.0\n",
       "4  1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Y_test).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "5d2d44292ee49a7ab4c3d566ee27b2e63895adec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: \t (100, 30) \n",
      "Y_train: \t (100,) \n",
      "X_test: \t (20, 30) \n",
      "Y_test: \t (20,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train: \\t\", X_train.shape, \"\\nY_train: \\t\", Y_train.shape, \"\\nX_test: \\t\", X_test.shape, \"\\nY_test: \\t\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "dabe6a9c526d2c175a901ae5ba817f1a7159ce81"
   },
   "outputs": [],
   "source": [
    "### Normalize the training and testing data.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "cb5140aa71086c4c69e10448f1f1b0af26081d2c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.055485</td>\n",
       "      <td>-0.753469</td>\n",
       "      <td>-0.121442</td>\n",
       "      <td>-0.164072</td>\n",
       "      <td>-1.194152</td>\n",
       "      <td>-0.876575</td>\n",
       "      <td>-0.827056</td>\n",
       "      <td>-0.545367</td>\n",
       "      <td>-0.767734</td>\n",
       "      <td>-1.128128</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.304937</td>\n",
       "      <td>-0.912142</td>\n",
       "      <td>-0.341934</td>\n",
       "      <td>-0.370332</td>\n",
       "      <td>-1.325803</td>\n",
       "      <td>-1.016305</td>\n",
       "      <td>-1.028702</td>\n",
       "      <td>-0.473441</td>\n",
       "      <td>-1.296842</td>\n",
       "      <td>-1.145820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.633965</td>\n",
       "      <td>-1.033798</td>\n",
       "      <td>1.642855</td>\n",
       "      <td>1.728069</td>\n",
       "      <td>0.342875</td>\n",
       "      <td>0.464608</td>\n",
       "      <td>1.280996</td>\n",
       "      <td>1.312964</td>\n",
       "      <td>0.036827</td>\n",
       "      <td>-0.644680</td>\n",
       "      <td>...</td>\n",
       "      <td>1.170658</td>\n",
       "      <td>-1.308804</td>\n",
       "      <td>1.193778</td>\n",
       "      <td>1.119295</td>\n",
       "      <td>0.219872</td>\n",
       "      <td>-0.373979</td>\n",
       "      <td>0.581328</td>\n",
       "      <td>0.599908</td>\n",
       "      <td>-0.905710</td>\n",
       "      <td>-0.489469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.359963</td>\n",
       "      <td>-0.744974</td>\n",
       "      <td>-0.335050</td>\n",
       "      <td>-0.410421</td>\n",
       "      <td>-1.304365</td>\n",
       "      <td>-0.179940</td>\n",
       "      <td>0.251546</td>\n",
       "      <td>-0.369043</td>\n",
       "      <td>-1.341897</td>\n",
       "      <td>-0.560035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.500265</td>\n",
       "      <td>-0.855047</td>\n",
       "      <td>-0.463588</td>\n",
       "      <td>-0.527180</td>\n",
       "      <td>-1.514012</td>\n",
       "      <td>-0.207956</td>\n",
       "      <td>0.268293</td>\n",
       "      <td>-0.212385</td>\n",
       "      <td>-1.531864</td>\n",
       "      <td>-0.863074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.068616</td>\n",
       "      <td>-1.484023</td>\n",
       "      <td>-1.045653</td>\n",
       "      <td>-0.944769</td>\n",
       "      <td>0.317555</td>\n",
       "      <td>-0.534964</td>\n",
       "      <td>-0.846574</td>\n",
       "      <td>-0.708789</td>\n",
       "      <td>0.003913</td>\n",
       "      <td>0.471973</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.987617</td>\n",
       "      <td>-1.462060</td>\n",
       "      <td>-0.984688</td>\n",
       "      <td>-0.865250</td>\n",
       "      <td>0.078943</td>\n",
       "      <td>-0.622702</td>\n",
       "      <td>-0.916325</td>\n",
       "      <td>-0.676515</td>\n",
       "      <td>0.077266</td>\n",
       "      <td>-0.459635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.287212</td>\n",
       "      <td>0.282899</td>\n",
       "      <td>-0.335825</td>\n",
       "      <td>-0.349861</td>\n",
       "      <td>-1.664048</td>\n",
       "      <td>-0.929881</td>\n",
       "      <td>-0.861213</td>\n",
       "      <td>-0.878901</td>\n",
       "      <td>-0.314254</td>\n",
       "      <td>-0.636541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.384228</td>\n",
       "      <td>0.462652</td>\n",
       "      <td>-0.376141</td>\n",
       "      <td>-0.438585</td>\n",
       "      <td>-0.943930</td>\n",
       "      <td>-0.625189</td>\n",
       "      <td>-0.960083</td>\n",
       "      <td>-1.010650</td>\n",
       "      <td>-0.351607</td>\n",
       "      <td>-0.658303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.055485 -0.753469 -0.121442 -0.164072 -1.194152 -0.876575 -0.827056   \n",
       "1  1.633965 -1.033798  1.642855  1.728069  0.342875  0.464608  1.280996   \n",
       "2 -0.359963 -0.744974 -0.335050 -0.410421 -1.304365 -0.179940  0.251546   \n",
       "3 -1.068616 -1.484023 -1.045653 -0.944769  0.317555 -0.534964 -0.846574   \n",
       "4 -0.287212  0.282899 -0.335825 -0.349861 -1.664048 -0.929881 -0.861213   \n",
       "\n",
       "         7         8         9     ...           20        21        22  \\\n",
       "0 -0.545367 -0.767734 -1.128128    ...    -0.304937 -0.912142 -0.341934   \n",
       "1  1.312964  0.036827 -0.644680    ...     1.170658 -1.308804  1.193778   \n",
       "2 -0.369043 -1.341897 -0.560035    ...    -0.500265 -0.855047 -0.463588   \n",
       "3 -0.708789  0.003913  0.471973    ...    -0.987617 -1.462060 -0.984688   \n",
       "4 -0.878901 -0.314254 -0.636541    ...    -0.384228  0.462652 -0.376141   \n",
       "\n",
       "         23        24        25        26        27        28        29  \n",
       "0 -0.370332 -1.325803 -1.016305 -1.028702 -0.473441 -1.296842 -1.145820  \n",
       "1  1.119295  0.219872 -0.373979  0.581328  0.599908 -0.905710 -0.489469  \n",
       "2 -0.527180 -1.514012 -0.207956  0.268293 -0.212385 -1.531864 -0.863074  \n",
       "3 -0.865250  0.078943 -0.622702 -0.916325 -0.676515  0.077266 -0.459635  \n",
       "4 -0.438585 -0.943930 -0.625189 -0.960083 -1.010650 -0.351607 -0.658303  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view normalised sample to check\n",
    "pd.DataFrame(X_train_norm).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "9e9cd67f0777be7bc80a4bf0b8372197171779b8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.516711</td>\n",
       "      <td>-0.129100</td>\n",
       "      <td>-1.497679</td>\n",
       "      <td>-1.219890</td>\n",
       "      <td>0.871600</td>\n",
       "      <td>-0.830237</td>\n",
       "      <td>-1.075434</td>\n",
       "      <td>-1.178987</td>\n",
       "      <td>1.331438</td>\n",
       "      <td>1.757914</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.457177</td>\n",
       "      <td>-0.441857</td>\n",
       "      <td>-1.442063</td>\n",
       "      <td>-1.124813</td>\n",
       "      <td>0.097127</td>\n",
       "      <td>-1.165725</td>\n",
       "      <td>-1.327422</td>\n",
       "      <td>-1.571106</td>\n",
       "      <td>0.428941</td>\n",
       "      <td>-0.192484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.664442</td>\n",
       "      <td>-0.226790</td>\n",
       "      <td>-0.687056</td>\n",
       "      <td>-0.644712</td>\n",
       "      <td>0.296704</td>\n",
       "      <td>-0.818565</td>\n",
       "      <td>-0.755887</td>\n",
       "      <td>-0.339178</td>\n",
       "      <td>-0.658021</td>\n",
       "      <td>0.012941</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.604697</td>\n",
       "      <td>-0.299119</td>\n",
       "      <td>-0.657242</td>\n",
       "      <td>-0.597786</td>\n",
       "      <td>-0.857554</td>\n",
       "      <td>-1.152854</td>\n",
       "      <td>-1.035383</td>\n",
       "      <td>-0.614524</td>\n",
       "      <td>-1.567889</td>\n",
       "      <td>-1.006820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.642886</td>\n",
       "      <td>-0.056894</td>\n",
       "      <td>-0.667285</td>\n",
       "      <td>-0.653207</td>\n",
       "      <td>-0.520214</td>\n",
       "      <td>-0.646802</td>\n",
       "      <td>-0.757792</td>\n",
       "      <td>-0.846169</td>\n",
       "      <td>-0.972531</td>\n",
       "      <td>-0.361447</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.616301</td>\n",
       "      <td>-0.058718</td>\n",
       "      <td>-0.653931</td>\n",
       "      <td>-0.610058</td>\n",
       "      <td>-0.207461</td>\n",
       "      <td>-0.479686</td>\n",
       "      <td>-0.625479</td>\n",
       "      <td>-0.647523</td>\n",
       "      <td>-0.612361</td>\n",
       "      <td>-0.275884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.298996</td>\n",
       "      <td>0.529248</td>\n",
       "      <td>-1.284072</td>\n",
       "      <td>-1.082878</td>\n",
       "      <td>0.648195</td>\n",
       "      <td>-0.775886</td>\n",
       "      <td>-0.831817</td>\n",
       "      <td>-0.878662</td>\n",
       "      <td>0.826759</td>\n",
       "      <td>0.524062</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.090116</td>\n",
       "      <td>0.880349</td>\n",
       "      <td>-1.108825</td>\n",
       "      <td>-0.924257</td>\n",
       "      <td>0.910880</td>\n",
       "      <td>-0.906867</td>\n",
       "      <td>-1.034381</td>\n",
       "      <td>-1.067431</td>\n",
       "      <td>-0.034241</td>\n",
       "      <td>-0.065011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.618564</td>\n",
       "      <td>0.316878</td>\n",
       "      <td>-1.529468</td>\n",
       "      <td>-1.267296</td>\n",
       "      <td>-0.122553</td>\n",
       "      <td>0.424541</td>\n",
       "      <td>0.496710</td>\n",
       "      <td>-0.661005</td>\n",
       "      <td>1.547207</td>\n",
       "      <td>3.226165</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.430102</td>\n",
       "      <td>0.651968</td>\n",
       "      <td>-1.402615</td>\n",
       "      <td>-1.108506</td>\n",
       "      <td>1.383675</td>\n",
       "      <td>1.031304</td>\n",
       "      <td>1.240324</td>\n",
       "      <td>-0.518465</td>\n",
       "      <td>0.737729</td>\n",
       "      <td>4.380271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -1.516711 -0.129100 -1.497679 -1.219890  0.871600 -0.830237 -1.075434   \n",
       "1 -0.664442 -0.226790 -0.687056 -0.644712  0.296704 -0.818565 -0.755887   \n",
       "2 -0.642886 -0.056894 -0.667285 -0.653207 -0.520214 -0.646802 -0.757792   \n",
       "3 -1.298996  0.529248 -1.284072 -1.082878  0.648195 -0.775886 -0.831817   \n",
       "4 -1.618564  0.316878 -1.529468 -1.267296 -0.122553  0.424541  0.496710   \n",
       "\n",
       "         7         8         9     ...           20        21        22  \\\n",
       "0 -1.178987  1.331438  1.757914    ...    -1.457177 -0.441857 -1.442063   \n",
       "1 -0.339178 -0.658021  0.012941    ...    -0.604697 -0.299119 -0.657242   \n",
       "2 -0.846169 -0.972531 -0.361447    ...    -0.616301 -0.058718 -0.653931   \n",
       "3 -0.878662  0.826759  0.524062    ...    -1.090116  0.880349 -1.108825   \n",
       "4 -0.661005  1.547207  3.226165    ...    -1.430102  0.651968 -1.402615   \n",
       "\n",
       "         23        24        25        26        27        28        29  \n",
       "0 -1.124813  0.097127 -1.165725 -1.327422 -1.571106  0.428941 -0.192484  \n",
       "1 -0.597786 -0.857554 -1.152854 -1.035383 -0.614524 -1.567889 -1.006820  \n",
       "2 -0.610058 -0.207461 -0.479686 -0.625479 -0.647523 -0.612361 -0.275884  \n",
       "3 -0.924257  0.910880 -0.906867 -1.034381 -1.067431 -0.034241 -0.065011  \n",
       "4 -1.108506  1.383675  1.031304  1.240324 -0.518465  0.737729  4.380271  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_test_norm).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3fa5002b44ac903a9a0de18c09994fe4ba0d89a7"
   },
   "source": [
    "<h1>1.2 Logistic Regression</h1>\n",
    "<h3>L1 regularisation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "45e26bac9d9c13671884b90e86696c1acf68ffa7"
   },
   "outputs": [],
   "source": [
    "### Train logistic regression models with L1 regularization and L2 regularization. Report accuracy, precision, recall, f1-score and print the confusion matrix.\n",
    "# Import packages\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score \n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "5e6e1073f63bce4f5c1cf0a6e209b6ac75e24f9e"
   },
   "outputs": [],
   "source": [
    "# Define Logistic Regression using L1 regularisation, alpha 0.1\n",
    "LR = LogisticRegression(penalty = 'l1', C=1/0.1) # The inverse of the regularisation strength, we need the inverse of the inverse, hence 1/0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "fbb850bce98e2f0bc1fc66b17c746d0620414589"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "LR.fit(X_train_norm, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "2f0a17eb59aa2aed7898b722e47d6257e5ed09d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 100.0 \n",
      "Precision Score = 1.0 \n",
      "Recall Score = 1.0 \n",
      "F1-score = 1.0 \n",
      "Confusion Matrix = \n",
      " [[42  0]\n",
      " [ 0 58]]\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "trained_predictions = LR.predict(X_train_norm)\n",
    "print(\"Accuracy Score = {}\".format(np.round(accuracy_score(Y_train,trained_predictions)*100,decimals=2)),\n",
    "      \"\\nPrecision Score = {}\".format(precision_score(Y_train,trained_predictions)),\n",
    "      \"\\nRecall Score = {}\".format(recall_score(Y_train,trained_predictions)),\n",
    "      \"\\nF1-score = {}\".format(f1_score(Y_train,trained_predictions)),\n",
    "      \"\\nConfusion Matrix = \\n\", confusion_matrix(Y_train,trained_predictions)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "438eb99348b514b034fb0611bb7704179e5de503"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 95.0 \n",
      "Precision Score = 0.9333333333333333 \n",
      "Recall Score = 1.0 \n",
      "F1-score = 0.9655172413793104 \n",
      "Confusion Matrix = \n",
      " [[ 5  1]\n",
      " [ 0 14]]\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "trained_predictions = LR.predict(X_test_norm)\n",
    "print(\"Accuracy Score = {}\".format(np.round(accuracy_score(Y_test,trained_predictions)*100,decimals=2)),\n",
    "      \"\\nPrecision Score = {}\".format(precision_score(Y_test,trained_predictions)),\n",
    "      \"\\nRecall Score = {}\".format(recall_score(Y_test,trained_predictions)),\n",
    "      \"\\nF1-score = {}\".format(f1_score(Y_test,trained_predictions)),\n",
    "      \"\\nConfusion Matrix = \\n\", confusion_matrix(Y_test,trained_predictions)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2f1584c0e06dca883e56e611615a3f51beee9604",
    "collapsed": true
   },
   "source": [
    "<h3>Using L2 regularisation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "cbf131c82989ce4d7a40c1654b586d3bc849734d"
   },
   "outputs": [],
   "source": [
    "# Define Logistic Regression using L2 regularisation with lambda = 0.1\n",
    "LR2 = LogisticRegression(penalty = 'l2', C=1/0.1) # The inverse of the regularisation strength, we need the inverse of the inverse, hence 1/0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "c52a38261cfc49f869963bc40e7accb835f30579"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "LR2.fit(X_train_norm, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "ccc1c5f5952541456d6926a40f16ec5e76710b76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 100.0 \n",
      "Precision Score = 1.0 \n",
      "Recall Score = 1.0 \n",
      "F1-score = 1.0 \n",
      "Confusion Matrix = \n",
      " [[42  0]\n",
      " [ 0 58]]\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "trained_predictions = LR2.predict(X_train_norm)\n",
    "print(\"Accuracy Score = {}\".format(np.round(accuracy_score(Y_train,trained_predictions)*100,decimals=2)),\n",
    "      \"\\nPrecision Score = {}\".format(precision_score(Y_train,trained_predictions)),\n",
    "      \"\\nRecall Score = {}\".format(recall_score(Y_train,trained_predictions)),\n",
    "      \"\\nF1-score = {}\".format(f1_score(Y_train,trained_predictions)),\n",
    "      \"\\nConfusion Matrix = \\n\", confusion_matrix(Y_train,trained_predictions)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "b23d3c1a5784c2667697bc74dae2634264129164"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 95.0 \n",
      "Precision Score = 0.9333333333333333 \n",
      "Recall Score = 1.0 \n",
      "F1-score = 0.9655172413793104 \n",
      "Confusion Matrix = \n",
      " [[ 5  1]\n",
      " [ 0 14]]\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "trained_predictions = LR2.predict(X_test_norm)\n",
    "print(\"Accuracy Score = {}\".format(np.round(accuracy_score(Y_test,trained_predictions)*100,decimals=2)),\n",
    "      \"\\nPrecision Score = {}\".format(precision_score(Y_test,trained_predictions)),\n",
    "      \"\\nRecall Score = {}\".format(recall_score(Y_test,trained_predictions)),\n",
    "      \"\\nF1-score = {}\".format(f1_score(Y_test,trained_predictions)),\n",
    "      \"\\nConfusion Matrix = \\n\", confusion_matrix(Y_test,trained_predictions)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ad8da8ea3bf7550e051e2c62a049e97b9c09eec1"
   },
   "source": [
    "Conclusion: for the dataset there appears to be no discernable difference between L1 and L2 regularisation using logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fb19839fedd5e31b33dc3f652d90d4506ec6e6a3"
   },
   "source": [
    "<h1>1.3 Choosing the best hyper-parameter</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "50b96cf6ad6c798df8109903fbd148472c4f93b3"
   },
   "source": [
    "Testing to find the best hyperparameter for L1 Regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "da2874dc431af434e8fbda160ff2ddbecbb8d1c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 = 0.9995\n",
      "1 = 0.9257500000000001\n",
      "3 = 0.9000000000000005\n",
      "10 = 0.9000000000000005\n",
      "33 = 0.9000000000000005\n",
      "100 = 0.9000000000000005\n",
      "333 = 0.925\n",
      "1000 = 0.42499999999999977\n",
      "3333 = 0.42499999999999977\n",
      "10000 = 0.42499999999999977\n",
      "33333 = 0.42499999999999977\n",
      "Maximum validation accuracy is 0.9995\n"
     ]
    }
   ],
   "source": [
    "# Import library for random splits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialise variables\n",
    "random_trials = 100 \n",
    "alpha_values = []\n",
    "np.random.seed(100)\n",
    "\n",
    "for alpha_set in [0.1,1,3,10,33,100,333,1000,3333,10000,33333]: # loop through required set of alpha values to find the \"best\" alpha value from the set (yielding the highest accuracy)\n",
    "    accuracy = [] # reset accuracy for each alpha value\n",
    "    \n",
    "    for i in range(0,random_trials):\n",
    "        # Splitting the TRAINING DATA only into training and validation data\n",
    "        x_train, x_validate, y_train, y_validate = train_test_split(X_train, Y_train, test_size=0.40, random_state=42)\n",
    "        \n",
    "        # Fitting logistic regression using L1 regularisation\n",
    "        lm = LogisticRegression(penalty='l1', C=1/alpha_set, verbose=0)\n",
    "        lm.fit(x_train, y_train)\n",
    "        \n",
    "        # Running predictions against the L1 regularisation model \n",
    "        true_labels = lm.predict(x_validate)\n",
    "        acc = accuracy_score(y_validate,true_labels)\n",
    "        accuracy.append(acc)\n",
    "    print(alpha_set, \"=\", np.mean(accuracy))\n",
    "    alpha_values.append(np.mean(accuracy))\n",
    "print('Maximum validation accuracy is {}'.format(max(alpha_values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d36f071469cafbebed7702566a87114869c1ab75"
   },
   "source": [
    "Conclusion: best hyperparameter is alpha of 0.1 with 0.9995 accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "5c4972c186eb861738ff0a993ac0506c6d825d5b"
   },
   "outputs": [],
   "source": [
    "### Retraining of the L1 regularisation logistic regression model with an alpha of 0.1\n",
    "LR_new_alpha = LogisticRegression(penalty = 'l1', C=1/0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_uuid": "ba637cf43c8688e91680550167816f69f7b2b6cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "LR_new_alpha.fit(X_train_norm, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_uuid": "6da82f5289643ae41cb810bf4dbdf0c5c2702abc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 95.0 \n",
      "Precision Score = 0.9333333333333333 \n",
      "Recall Score = 1.0 \n",
      "F1-score = 0.9655172413793104 \n",
      "Confusion Matrix = \n",
      " [[ 5  1]\n",
      " [ 0 14]]\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "trained_predictions = LR2.predict(X_test_norm)\n",
    "print(\"Accuracy Score = {}\".format(np.round(accuracy_score(Y_test,trained_predictions)*100,decimals=2)),\n",
    "      \"\\nPrecision Score = {}\".format(precision_score(Y_test,trained_predictions)),\n",
    "      \"\\nRecall Score = {}\".format(recall_score(Y_test,trained_predictions)),\n",
    "      \"\\nF1-score = {}\".format(f1_score(Y_test,trained_predictions)),\n",
    "      \"\\nConfusion Matrix = \\n\", confusion_matrix(Y_test,trained_predictions)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0\n",
      "9   0.145333\n",
      "15  0.000000\n",
      "11  0.000000\n",
      "19  0.000000\n",
      "18  0.000000\n"
     ]
    }
   ],
   "source": [
    "# The top 5 features selected in decreasing order of magnitude\n",
    "top_features = LR_new_alpha.coef_\n",
    "sorted_top_5 = pd.DataFrame(top_features.T)\n",
    "sorted_top_5.sort_values(by=[0], axis=0, ascending=False, inplace=True)\n",
    "print(sorted_top_5.head(n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highest accuracy of the L1 model is 95% with alpha of 0.1. Precision was 93% identifying the fraction correctly identified. Recall was especially high at 100%. The confusion matrix shows only 1 incorrectly predicted item returning a negative diagnosis whilst having an positive diagnosis (a false positive). The top 5 features are ranked 9, 15, 11, 19, 18 and are positive weight ascending order.\n",
    "\n",
    "For the above model there are signs of underfitting as the original model using logistic regression on the training and test data achieved 100% whilst this model only achieved 95% accuracy. The model had 1 error in the confusion matrix (1 of 20) with F1-score and precision being lower.\n",
    "\n",
    "Reasoning why the model fit with such high accuracy is due to the small amount of values within the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0d4ec0cf7e51536bec5234b97bd283c3e368ba04"
   },
   "source": [
    "<h2>Testing to find the best hyperparameter for L2 Regularisation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_uuid": "5af18693c8d95a523edea41d2ba899b55ee6442b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 = 0.9749999999999995\n",
      "0.003 = 0.9749999999999995\n",
      "0.01 = 0.9749999999999995\n",
      "0.03 = 0.9749999999999995\n",
      "0.1 = 1.0\n",
      "0.3 = 0.9749999999999995\n",
      "1 = 0.9749999999999995\n",
      "3 = 0.95\n",
      "10 = 0.9000000000000005\n",
      "33 = 0.9000000000000005\n",
      "Maximum validation accuracy is 1.0\n"
     ]
    }
   ],
   "source": [
    "# Initialise variables\n",
    "random_trials = 100 \n",
    "lambda_values = []\n",
    "np.random.seed(100)\n",
    "\n",
    "for lambda_set in [0.001,0.003,0.01,0.03,0.1,0.3,1,3,10,33]: # loop through required set of lambda values to find the \"best\" lambda value from the set (yielding the highest accuracy)\n",
    "    accuracy = [] # reset accuracy for each alpha value\n",
    "    \n",
    "    for i in range(0,random_trials):\n",
    "        # Splitting the TRAINING DATA only into training and validation data\n",
    "        x_train, x_validate, y_train, y_validate = train_test_split(X_train, Y_train, test_size=0.40, random_state=42)\n",
    "        \n",
    "        # Fitting logistic regression using L2 regularisation\n",
    "        lm = LogisticRegression(penalty='l2', C=1/lambda_set, random_state=42) # verbose set to zero to try and stop the errors appearing around convergence (although it is meant to be zero by default)\n",
    "        lm.fit(x_train, y_train)\n",
    "        \n",
    "        # Running predictions against the L2 regularisation model \n",
    "        true_labels = lm.predict(x_validate)\n",
    "        acc = accuracy_score(y_validate,true_labels)\n",
    "        accuracy.append(acc)\n",
    "    print(lambda_set, \"=\", np.mean(accuracy))\n",
    "    lambda_values.append(np.mean(accuracy))\n",
    "print('Maximum validation accuracy is {}'.format(max(lambda_values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9b9c0ed14e197aa1e6f8ce31b43ab252417eb79f"
   },
   "source": [
    "Conclusion: maximum validation accuracy is when lambda = 0.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_uuid": "5263d273ac57e313c001bd09f0abf7a62c3c5345"
   },
   "outputs": [],
   "source": [
    "# Define Logistic Regression using L2 regularisation with lambda = 0.1\n",
    "LR_new_lambda = LogisticRegression(penalty = 'l2', C=1/0.1) # The inverse of the regularisation strength, we need the inverse of the inverse, hence 1/0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_uuid": "4c54c72231502a21e80afdc1f3b529054243ae13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "LR_new_lambda.fit(X_train_norm, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 95.0 \n",
      "Precision Score = 0.9333333333333333 \n",
      "Recall Score = 1.0 \n",
      "F1-score = 0.9655172413793104 \n",
      "Confusion Matrix = \n",
      " [[ 5  1]\n",
      " [ 0 14]]\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data using optimal lambda\n",
    "trained_predictions = LR_new_lambda.predict(X_test_norm)\n",
    "print(\"Accuracy Score = {}\".format(np.round(accuracy_score(Y_test,trained_predictions)*100,decimals=2)),\n",
    "      \"\\nPrecision Score = {}\".format(precision_score(Y_test,trained_predictions)),\n",
    "      \"\\nRecall Score = {}\".format(recall_score(Y_test,trained_predictions)),\n",
    "      \"\\nF1-score = {}\".format(f1_score(Y_test,trained_predictions)),\n",
    "      \"\\nConfusion Matrix = \\n\", confusion_matrix(Y_test,trained_predictions)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0\n",
      "9   0.958875\n",
      "18  0.823487\n",
      "15  0.587962\n",
      "16  0.351436\n",
      "4   0.328829\n"
     ]
    }
   ],
   "source": [
    "# The top 5 features selected in decreasing order of magnitude for \n",
    "top_features = LR_new_lambda.coef_\n",
    "sorted_top_5 = pd.DataFrame(top_features.T)\n",
    "sorted_top_5.sort_values(by=[0], axis=0, ascending=False, inplace=True)\n",
    "print(sorted_top_5.head(n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highest accuracy of the L2 model is 95% with lmabda of 0.1. Precision was 93% identifying the fraction correctly identified. Recall was especially high at 100%. The confusion matrix shows only 1 incorrectly predicted item returning a negative diagnosis whilst having an positive diagnosis (a false positive). The top 5 features are ranked 9, 18, 15, 16, 4 and are positive weight ascending order.\n",
    "\n",
    "For the above model there are signs of underfitting as the original model using logistic regression on the training and test data achieved 100% whilst this model only achieved 95% accuracy. The model had 1 error in the confusion matrix (1 of 20) with F1-score and precision being lower.\n",
    "\n",
    "Reasoning why the model fit with such high accuracy is due to the small amount of values within the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Task B Multiclass Classification</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.1 Read and understand the data, create a default One-vs-Rest Classifier</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Part 1</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in file\n",
    "rmnist = pd.read_csv(\"C:/Personal/University/2018_T2 - SIT720 - Machine Learning/Assessment 2/reduced_mnist.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points: \t\t (2520, 785) \n",
      "Total number of features: \t 785 \n",
      "Unique labels in the data: \t 10 \n",
      "Unique labes are: \t\t [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of data points: \\t\\t\", rmnist.shape, \n",
    "      \"\\nTotal number of features: \\t\", len(rmnist.columns),\n",
    "      \"\\nUnique labels in the data: \\t\", len(np.unique(rmnist.iloc[:,0])),\n",
    "      \"\\nUnique labes are: \\t\\t\", np.unique(rmnist.iloc[:,0])\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features includes the feature we are predicting. If we remove this (785 - 1) then we have 784 features to predict / classify with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Part 2</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples:\t1764\n",
      "Number of testing samples:\t756\n"
     ]
    }
   ],
   "source": [
    "# Splitting into 70% training and 30% testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split into a training and testing set\n",
    "X = rmnist.drop('label', axis = 1)\n",
    "Y = rmnist['label']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30, random_state=42)\n",
    "\n",
    "print(f\"Number of training samples:\\t{len(X_train)}\")\n",
    "print(f\"Number of testing samples:\\t{len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A One-vs-Rest Classifier (which uses Logistic regression classifier with alpha=1) on training data, and report accuracy, precision, recall on testing data.\n",
    "\n",
    "# Import packages\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Create model using L1 regularisation and alpha of 1\n",
    "one_v_rest = OneVsRestClassifier(LogisticRegression(penalty = 'l1', C = 1, multi_class = 'ovr'))\n",
    "\n",
    "# Fit model\n",
    "one_v_rest.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score = 84.52 \n",
      "Precision Score = 0.8494265442868871 \n",
      "Recall Score = 0.8452380952380952 \n",
      "F1-score = 0.8453954224202409 \n",
      "Confusion Matrix = \n",
      " [[78  1  0  0  0  2  0  0  3  0]\n",
      " [ 0 90  0  0  0  0  0  0  2  0]\n",
      " [ 2  3 60  0  1  0  2  4  4  3]\n",
      " [ 0  1  2 67  1  3  0  0  4  0]\n",
      " [ 0  1  2  1 53  0  3  0  1 12]\n",
      " [ 2  0  0  6  0 56  3  0  6  1]\n",
      " [ 0  0  0  0  3  0 63  0  0  0]\n",
      " [ 0  0  0  1  1  0  0 64  3  4]\n",
      " [ 1  1  1  1  0  9  1  0 57  2]\n",
      " [ 0  0  2  0  3  2  0  3  3 51]]\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "trained_predictions = one_v_rest.predict(X_test)\n",
    "print(\"Accuracy Score = {}\".format(np.round(accuracy_score(Y_test,trained_predictions)*100,decimals=2)),\n",
    "      \"\\nPrecision Score = {}\".format(precision_score(Y_test,trained_predictions, average='weighted')),\n",
    "      \"\\nRecall Score = {}\".format(recall_score(Y_test,trained_predictions, average='weighted')),\n",
    "      \"\\nF1-score = {}\".format(f1_score(Y_test,trained_predictions, average='weighted')),\n",
    "      \"\\nConfusion Matrix = \\n\", confusion_matrix(Y_test,trained_predictions)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2.2 Choosing the best hyper-parameter</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Part 1</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- As in section 1.3 above, now create 10 random splits of training data into training and validation data. Choose the\n",
    "best value of alpha from the following set: {0.1, 1, 3, 10, 33, 100, 333, 1000, 3333, 10000, 33333}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 \tTest accuracy =\t 0.8358 \tTrain accuracy =\t 1.0000\n",
      "1 \tTest accuracy =\t 0.8408 \tTrain accuracy =\t 1.0000\n",
      "3 \tTest accuracy =\t 0.8285 \tTrain accuracy =\t 1.0000\n",
      "10 \tTest accuracy =\t 0.8287 \tTrain accuracy =\t 1.0000\n",
      "33 \tTest accuracy =\t 0.8387 \tTrain accuracy =\t 1.0000\n",
      "100 \tTest accuracy =\t 0.8498 \tTrain accuracy =\t 0.9994\n",
      "333 \tTest accuracy =\t 0.8551 \tTrain accuracy =\t 0.9674\n",
      "1000 \tTest accuracy =\t 0.8483 \tTrain accuracy =\t 0.9176\n",
      "3333 \tTest accuracy =\t 0.7932 \tTrain accuracy =\t 0.8438\n",
      "10000 \tTest accuracy =\t 0.6966 \tTrain accuracy =\t 0.7331\n",
      "33333 \tTest accuracy =\t 0.5251 \tTrain accuracy =\t 0.5628\n",
      "\n",
      "Maximum validation accuracy is 0.8550943396226416\n",
      "\n",
      "Maximum training accuracy is 1.0\n"
     ]
    }
   ],
   "source": [
    "# Adjusted code from 1.3 above.\n",
    "\n",
    "# Initialise variables\n",
    "random_trials = 10\n",
    "validation_accuracy = []\n",
    "training_accuracy = []\n",
    "np.random.seed(100)\n",
    "\n",
    "for alpha_set in [0.1,1,3,10,33,100,333,1000,3333,10000,33333]: # loop through required set of alpha values to find the \"best\" alpha value from the set (yielding the highest accuracy)\n",
    "    true_accuracy = [] # reset accuracy for each alpha value\n",
    "    train_accuracy = [] # reset accuracy for each alpha value\n",
    "    random_mean = [] # reset random_split for each alpha value\n",
    "    \n",
    "    for i in range(0,random_trials):\n",
    "        # Creating a random value to split into training and testing\n",
    "        random_split = 0.3 #np.random.uniform(0, 1) <- for a truly random split\n",
    "        \n",
    "        # Splitting the TRAINING DATA only into training and validation data\n",
    "        x_train, x_validate, y_train, y_validate = train_test_split(X_train, Y_train, test_size=random_split)\n",
    "        \n",
    "        # Fitting logistic regression using L1 regularisation\n",
    "        lm = LogisticRegression(penalty='l1', C=1/alpha_set, verbose=0)\n",
    "        lm.fit(x_train, y_train)\n",
    "        \n",
    "        # Running predictions against the L1 regularisation model - validation predictions\n",
    "        true_labels = lm.predict(x_validate)\n",
    "        acc = accuracy_score(y_validate,true_labels)\n",
    "        train_labels = lm.predict(x_train)\n",
    "        train_acc = accuracy_score(y_train,train_labels)\n",
    "        \n",
    "        # Updating values for mean\n",
    "        true_accuracy.append(acc)\n",
    "        train_accuracy.append(train_acc)\n",
    "        random_mean.append(random_split)\n",
    "    \n",
    "    # Print out the results of each alpha value\n",
    "    print(alpha_set, \"\\tTest accuracy =\\t %.4f\" % np.mean(true_accuracy), \"\\tTrain accuracy =\\t %.4f\" % np.mean(train_accuracy))#, \"\\trandom split mean =\\t %.4f\" % np.mean(random_mean))\n",
    "\n",
    "    # Update means\n",
    "    validation_accuracy.append(np.mean(true_accuracy))\n",
    "    training_accuracy.append(np.mean(train_accuracy))\n",
    "    \n",
    "print('\\nMaximum validation accuracy is {}'.format(max(validation_accuracy)))\n",
    "print('\\nMaximum training accuracy is {}'.format(max(training_accuracy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum validation accuracy of 85.5% was achieved with an alpha of 333."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot of training accuracy\n",
    "plt.plot(validation_accuracy,color='blue')\n",
    "plt.plot(training_accuracy, color='red')\n",
    "plt.xlabel('Alpha Value - index')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_value_index = [0.1,1,3,10,33,100,333,1000,3333,10000,33333]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data is red, testing data is blue. Overfitting can be seen when the training accuracy is high and the testing accuracy is low (lower indexes below 5 - alpha of 33). Alignment between the training and testing curves doesn't appear to happen on the above graph until index value 7 (alpha of 1000).\n",
    "\n",
    "The highest test accuracy occurs around an alpha of 333. With accuracy dropping at this point this is the optimum level (out of the designated alphas) for this dataset and model type balancing between bias and variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>2.2 Part 2</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix = \n",
      " [[78  1  0  0  0  2  0  0  3  0]\n",
      " [ 0 90  0  0  0  0  0  0  2  0]\n",
      " [ 2  3 60  0  1  0  2  4  4  3]\n",
      " [ 0  1  2 67  1  3  0  0  4  0]\n",
      " [ 0  1  2  1 53  0  3  0  1 12]\n",
      " [ 2  0  0  6  0 56  3  0  6  1]\n",
      " [ 0  0  0  0  3  0 63  0  0  0]\n",
      " [ 0  0  0  1  1  0  0 64  3  4]\n",
      " [ 1  1  1  1  0  9  1  0 57  2]\n",
      " [ 0  0  2  0  3  2  0  3  3 51]]\n"
     ]
    }
   ],
   "source": [
    "# The confusion matrix - Total number of non-zero features in the final model.\n",
    "lm_confusion_matrix = confusion_matrix(Y_test,trained_predictions)\n",
    "print(\"\\nConfusion Matrix = \\n\", lm_confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority of predictions are on the diagonal matching an identity matrix. Model generalisation aligns well to the dataset with 85.5% accuracy. Highest errors are for classes 2 and 4. Class 4 in particular has 12 incorrectly labelled as 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 Accuracy =\t0.9398 \tPrecision =\t0.9286 \tRecall =\t0.4845\n",
      "Class 1 Accuracy =\t0.9278 \tPrecision =\t0.9783 \tRecall =\t0.4813\n",
      "Class 2 Accuracy =\t0.8955 \tPrecision =\t0.7595 \tRecall =\t0.4724\n",
      "Class 3 Accuracy =\t0.8816 \tPrecision =\t0.8590 \tRecall =\t0.4685\n",
      "Class 4 Accuracy =\t0.8548 \tPrecision =\t0.7260 \tRecall =\t0.4609\n",
      "Class 5 Accuracy =\t0.7778 \tPrecision =\t0.7568 \tRecall =\t0.4375\n",
      "Class 6 Accuracy =\t0.8750 \tPrecision =\t0.9545 \tRecall =\t0.4667\n",
      "Class 7 Accuracy =\t0.9014 \tPrecision =\t0.8767 \tRecall =\t0.4741\n",
      "Class 8 Accuracy =\t0.6867 \tPrecision =\t0.7808 \tRecall =\t0.4071\n",
      "Class 9 Accuracy =\t0.6986 \tPrecision =\t0.7969 \tRecall =\t0.4113\n"
     ]
    }
   ],
   "source": [
    "# Precision, recall and accuracy for each class in the confusion matrix\n",
    "\n",
    "counter = 0\n",
    "false_neg = []\n",
    "actual = confusion_matrix(trained_predictions,trained_predictions) # 100% accuracy to measure from\n",
    "\n",
    "# Calculate values\n",
    "for i in range (0,10):\n",
    "    for j in range (0,10):\n",
    "        #print(lm_confusion_matrix[i][j])\n",
    "        counter = counter + lm_confusion_matrix[i][j]\n",
    "        \n",
    "    # Inner loop to grab false negatives for calculation\n",
    "    for neg in range (0,10):\n",
    "        false_neg.append(lm_confusion_matrix[neg][i])\n",
    "        \n",
    "    print('Class', i,\n",
    "          'Accuracy =\\t%.4f' % (lm_confusion_matrix[i][i]/actual[i][i]),\n",
    "          '\\tPrecision =\\t%.4f' % (lm_confusion_matrix[i][i]/counter), # True positive / (True positive + False positive)\n",
    "          '\\tRecall =\\t%.4f' % (lm_confusion_matrix[i][i]/(lm_confusion_matrix[i][i] + sum(false_neg))) # True positive / (True positive + False negative)\n",
    "         )\n",
    "    counter = 0\n",
    "    false_neg = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most accurate class is Class 0 with 93.98% accuracy. Class with the most classification errors is Class 8 with 68.67% accuracy.\n",
    "\n",
    "Possible overfitting with several classes as they are much higher than the 84.52% achieved earlier for accuracy on the One versus Rest Classifier. Underfitting also present with accuracy scores for Class 8 and 9 significantly lower than the One versus Rest Classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
